{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df373e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bs4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37fcc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a66533",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 1: Requesting the web page of wikipedia.\n",
    "wiki_page = requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "wiki_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e546ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(wiki_page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2a4e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "heading_tags = [\"h1\",\"h2\",\"h3\"]\n",
    "\n",
    "for i in soup.find_all(heading_tags):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4364fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e2d0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Requesting for the webpage of IMDB TOP movies.\n",
    "page_imdb = requests.get('https://www.imdb.com/chart/top/')\n",
    "page_imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01560f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_imdb = BeautifulSoup(page_imdb.content)\n",
    "soup_imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0ff193",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping the names.\n",
    "scraped_movies = soup_imdb.find_all('td',class_=\"titleColumn\")\n",
    "scraped_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63165bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating For loop to remove the text.\n",
    "movies = []\n",
    "for movie in scraped_movies:\n",
    "    movie = movie.get_text().replace('\\n', \"\")\n",
    "    movie = movie.strip(\"  \")\n",
    "    movies.append(movie)\n",
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63b9801",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping the ratings.\n",
    "scraped_ratings = soup_imdb.find_all('td', class_=\"ratingColumn imdbRating\")\n",
    "scraped_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5680bed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating For loop to remove the text.\n",
    "ratings = []\n",
    "for rating in scraped_ratings:\n",
    "    rating = rating.get_text().replace('\\n', \"\")\n",
    "    rating = rating.strip(\"  \")\n",
    "    ratings.append(rating)\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2913b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Dataset.\n",
    "data = pd.DataFrame()\n",
    "data['Movie Names'] = movies\n",
    "data['Ratings'] = ratings\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724fcc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Requesting for the webpage of IMDB Top Indian Movies.\n",
    "page_indian = requests.get('https://www.imdb.com/india/top-rated-indian-movies/')\n",
    "page_indian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e53498",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_indian = BeautifulSoup(page_indian.content)\n",
    "soup_indian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1da501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the movie names\n",
    "scraped_indian_movies = soup_indian.find_all('td',class_=\"titleColumn\")\n",
    "scraped_indian_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16673a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating For loop to remove the text.\n",
    "indianmovies = []\n",
    "for indianmovie in scraped_indian_movies:\n",
    "    indianmovie = indianmovie.get_text().replace('\\n', \"\")\n",
    "    indianmovie = indianmovie.strip(\"  \")\n",
    "    indianmovies.append(indianmovie)\n",
    "indianmovies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ecd336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping movie ratings.\n",
    "scraped_indianratings = soup_indian.find_all('td', class_=\"ratingColumn imdbRating\")\n",
    "scraped_indianratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7914f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating For loop to remove the text.\n",
    "indianratings = []\n",
    "for indianrating in scraped_indianratings:\n",
    "    indianrating = indianrating.get_text().replace('\\n', \"\")\n",
    "    indianrating = indianrating.strip(\"  \")\n",
    "    indianratings.append(indianrating)\n",
    "indianratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff627ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Dataset.\n",
    "data_indian = pd.DataFrame()\n",
    "data_indian['Movie Names'] = indianmovies\n",
    "data_indian['Ratings'] = indianratings\n",
    "data_indian.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef844de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Requesting for the webpage of meesho.\n",
    "page_meesho = requests.get('https://meesho.com/bags-ladies/pl/p7vbp')\n",
    "page_meesho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc14033",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_meesho = BeautifulSoup(page_meesho.content)\n",
    "soup_meesho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b4cc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the product names.\n",
    "scraped_names = soup_meesho.find_all('p',class_=\"Text__StyledText-sc-oo0kvp-0 bWSOET NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS\")\n",
    "scraped_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195db336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating For loop to remove the text.\n",
    "names = []\n",
    "for name in scraped_names:\n",
    "    name = name.get_text().replace('\\n', \"\")\n",
    "    name = name.strip(\"  \")\n",
    "    names.append(name)\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87da346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the data for prices\n",
    "scraped_prices = soup_meesho.find_all('h5',class_=\"Text__StyledText-sc-oo0kvp-0 hiHdyy\")\n",
    "scraped_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d0e4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating For loop to remove the text.\n",
    "prices = []\n",
    "for price in scraped_prices:\n",
    "    price = price.get_text().replace('₹', \"\")\n",
    "    price = price.strip(\"  \")\n",
    "    prices.append(price)\n",
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d72b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the data for Discounts.\n",
    "scraped_discounts = soup_meesho.find_all('span',class_=\"Text__StyledText-sc-oo0kvp-0 lnonyH\")\n",
    "scraped_discounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04357571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating For loop to remove the text.\n",
    "discounts = []\n",
    "for discount in scraped_discounts:\n",
    "    discount = discount.get_text().replace('₹', \"\")\n",
    "    discount = discount.strip(\"  \")\n",
    "    discounts.append(discount)\n",
    "discounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415af530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the length of each scrapped data to create the data set.\n",
    "print(len(names),len(prices),len(discounts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9957b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the data set.\n",
    "df = pd.DataFrame({'Product name': names,'Prices': prices,'Discounts': discounts})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56415cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Requesting the webpage of coreyms for scraping the data.\n",
    "page_coreyms = requests.get('https://coreyms.com/')\n",
    "page_coreyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0821cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_coreyms = BeautifulSoup(page_coreyms.content)\n",
    "soup_coreyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f081ae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the data for headings\n",
    "scraped_titles = soup_coreyms.find_all('h2',class_=\"entry-title\")\n",
    "scraped_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4dec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating For loop to remove the text.\n",
    "titles = []\n",
    "for title in scraped_titles:\n",
    "    title = title.get_text().replace('\\n', \"\")\n",
    "    title = title.strip(\"  \")\n",
    "    titles.append(title)\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1647b299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the data for Dates.\n",
    "scraped_dates = soup_coreyms.find_all('time', class_=\"entry-time\")\n",
    "scraped_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede313fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating For loop to remove the text.\n",
    "dates = []\n",
    "for date in scraped_dates:\n",
    "    date = date.get_text().replace('\\n', \"\")\n",
    "    date = date.strip(\"  \")\n",
    "    dates.append(date)\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacf2805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the data for contents.\n",
    "scraped_contents = soup_coreyms.find_all('div', class_=\"entry-content\")\n",
    "scraped_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9ee660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating For loop to remove the text.\n",
    "contents = []\n",
    "for content in scraped_contents:\n",
    "    content = content.get_text().replace('\\n', \"\")\n",
    "    content = content.strip(\"  \")\n",
    "    contents.append(content)\n",
    "contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100476ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the data for Videos.\n",
    "scraped_videos = []\n",
    "for i in soup_coreyms.find_all('iframe', class_=\"youtube-player\"):\n",
    "    scraped_videos.append(i['src'])\n",
    "\n",
    "scraped_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80245fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Requesting the webpage of NOBROKER for scraping the data. \n",
    "page_nobroker = requests.get('https://www.nobroker.in/property/sale/bangalore/multiple?searchParam=W3sibGF0IjoxMi45NzgzNjkyLCJsb24iOjc3LjY0MDgzNTYsInBsYWNlSWQiOiJDaElKa1FOM0dLUVdyanNSTmhCUUpyaEdEN1UiLCJwbGFjZU5hbWUiOiJJbmRpcmFuYWdhciIsInNob3dNYXAiOmZhbHNlfSx7ImxhdCI6MTIuOTMwNzczNSwibG9uIjo3Ny41ODM4MzAyLCJwbGFjZUlkIjoiQ2hJSjJkZGxaNWdWcmpzUmgxQk9BYWYtb3JzIiwicGxhY2VOYW1lIjoiSmF5YW5hZ2FyIiwic2hvd01hcCI6ZmFsc2V9LHsibGF0IjoxMi45OTgxNzMyLCJsb24iOjc3LjU1MzA0NDU5OTk5OTk5LCJwbGFjZUlkIjoiQ2hJSnhmVzREUE05cmpzUktzTlRHLTVwX1FRIiwicGxhY2VOYW1lIjoiUmFqYWppbmFnYXIiLCJzaG93TWFwIjpmYWxzZX1d')\n",
    "page_nobroker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5acb26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_nobroker = BeautifulSoup(page_nobroker.content)\n",
    "soup_nobroker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e5d2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the data for house names.\n",
    "scraped_housenames = soup_nobroker.find_all('span',class_=\"overflow-hidden overflow-ellipsis whitespace-nowrap max-w-80pe po:max-w-full\")\n",
    "scraped_housenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e137c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating For loop to remove the text.\n",
    "housenames = []\n",
    "for housename in scraped_housenames:\n",
    "    housename = housename.get_text().replace('\\n', \"\")\n",
    "    housename = housename.strip(\"  \")\n",
    "    housenames.append(housename)\n",
    "housenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceaa7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the data for locations.\n",
    "scraped_houselocations = soup_nobroker.find_all('div',class_=\"mt-0.5p overflow-hidden overflow-ellipsis whitespace-nowrap max-w-70 text-gray-light leading-4 po:mb-0 po:max-w-95\")\n",
    "scraped_houselocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be490baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating For loop to remove the text.\n",
    "houselocations = []\n",
    "for houselocation in scraped_houselocations:\n",
    "    houselocation = houselocation.get_text().replace('\\n', \"\")\n",
    "    houselocation = houselocation.strip(\"  \")\n",
    "    houselocations.append(houselocation)\n",
    "houselocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6040a918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the data for house details.\n",
    "scraped_housedetails = soup_nobroker.find_all('div',class_=\"flex flex-col w-33pe items-center bo tp:w-half po:w-full border-r-0\")\n",
    "scraped_housedetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c0feca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating For loop to remove the text.\n",
    "housedetails = []\n",
    "for housedetail in scraped_housedetails:\n",
    "    housedetail = housedetail.get_text().replace('\\n', \"\")\n",
    "    housedetail = housedetail.strip(\"  \")\n",
    "    housedetails.append(housedetail)\n",
    "housedetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c181c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the lenght of each scrapped data for creating the data set.\n",
    "print(len(housenames),len(houselocations),len(housedetails))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4aa74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the data set.\n",
    "df_house = pd.DataFrame({'House title': housenames,'Location': houselocations,'Price': housedetails})\n",
    "df_house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5d02a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Requesting the webpage of Dineout for scraping the data.\n",
    "page_dine = requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "page_dine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82ded78",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_dine = BeautifulSoup(page_dine.content)\n",
    "soup_dine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1618cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the data for Restaurant names. \n",
    "scraped_dinenames = soup_dine.find_all('div',class_=\"restnt-info cursor\")\n",
    "scraped_dinenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45944755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating For loop to remove the text.\n",
    "restaurants = []\n",
    "for restaurant in scraped_dinenames:\n",
    "    restaurant = restaurant.get_text().replace('\\n', \"\")\n",
    "    restaurant = restaurant.strip(\"  \")\n",
    "    restaurants.append(restaurant)\n",
    "restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c99576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the data for locations.\n",
    "scraped_dinelocations = soup_dine.find_all('div',class_=\"restnt-loc ellipsis\")\n",
    "scraped_dinelocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a564d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating For loop to remove the text.\n",
    "restaurant_locations = []\n",
    "for restaurant_location in scraped_dinelocations:\n",
    "    restaurant_location = restaurant_location.get_text().replace('\\n', \"\")\n",
    "    restaurant_location = restaurant_location.strip(\"  \")\n",
    "    restaurant_locations.append(restaurant_location)\n",
    "restaurant_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4051bdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the data for details.\n",
    "scraped_dinedetails = soup_dine.find_all('div',class_=\"detail-info\")\n",
    "scraped_dinedetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef939a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating For loop to remove the text.\n",
    "restaurant_details = []\n",
    "for restaurant_detail in scraped_dinedetails:\n",
    "    restaurant_detail = restaurant_detail.get_text().replace('\\n', \"\")\n",
    "    restaurant_detail = restaurant_detail.strip(\"  \")\n",
    "    restaurant_details.append(restaurant_detail)\n",
    "restaurant_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0e43e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the data for ratings.\n",
    "scraped_dineratings = soup_dine.find_all('div',class_=\"restnt-rating rating-4\")\n",
    "scraped_dineratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff5b98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating For loop to remove the text.\n",
    "restaurant_ratings = []\n",
    "for restaurant_rating in scraped_dineratings:\n",
    "    restaurant_rating = restaurant_rating.get_text().replace('\\n', \"\")\n",
    "    restaurant_rating = restaurant_rating.strip(\"  \")\n",
    "    restaurant_ratings.append(restaurant_rating)\n",
    "restaurant_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af629fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the data for images.\n",
    "scraped_dineimages = soup_dine.find_all('img',class_=\"no-img\")\n",
    "scraped_dineimages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3931bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating For loop to remove the text.\n",
    "restaurant_images = []\n",
    "for restaurant_image in scraped_dineimages:\n",
    "    restaurant_images.append(restaurant_image['data-src'])\n",
    "restaurant_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43ba386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the length of each scrapped data for creating the data set.\n",
    "print(len(restaurants),len(restaurant_locations),len(restaurant_details),len(restaurant_ratings),len(restaurant_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63a93f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the data set.\n",
    "df_restaurants = pd.DataFrame({'Restaurant name': restaurants,'Cuisine and Prices': restaurant_details,'Location': restaurant_locations,'Ratings': restaurant_ratings,'Image URL': restaurant_images})\n",
    "df_restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cf0157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Requesting the Webpage of Bewakoof for scraping the data. \n",
    "page_bewakoof = requests.get('https://www.bewakoof.com/men-clothing/category-t-shirt')\n",
    "page_bewakoof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e45431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_bewakoof = BeautifulSoup(page_bewakoof.content)\n",
    "soup_bewakoof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadb00a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_name = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc825f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the names of products.\n",
    "for a in soup_bewakoof.find_all('div',class_=\"productCardBox\"):\n",
    "    name = a.find('h3')\n",
    "    products_name.append(name.text)\n",
    "products_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72824a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the prices.\n",
    "s_prices = soup_bewakoof.find_all('span',class_=\"discountedPriceText\")\n",
    "s_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6f1de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating For loop to remove the text.\n",
    "shirts_prices = []\n",
    "for shirts_price in s_prices:\n",
    "    shirts_price = shirts_price.get_text().replace('₹', \"\")\n",
    "    shirts_prices.append(shirts_price)\n",
    "shirts_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea10f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the actual prices.\n",
    "a_prices = soup_bewakoof.find_all('span',class_=\"actualPriceText\")\n",
    "a_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5054072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating For loop to remove the text.\n",
    "actual_prices = []\n",
    "for aprice in a_prices:\n",
    "    aprice = aprice.get_text().replace('₹', \"\")\n",
    "    actual_prices.append(aprice)\n",
    "actual_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f5b76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the data for images.\n",
    "s_img = soup_bewakoof.find_all('img',class_=\"productImgTag\")\n",
    "s_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a99e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating For loop to remove the text.\n",
    "shirts_images = []\n",
    "for image1 in s_img:\n",
    "    shirts_images.append(image1['src'])\n",
    "shirts_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10657eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the lenght of the scraped data for creating the data set.\n",
    "print(len(products_name),len(shirts_prices),len(actual_prices), len(shirts_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e98e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crating the data set.\n",
    "df_shirts = pd.DataFrame({'Product name': products_name,'Prices': shirts_prices,'Actual Price': actual_prices,'Image URL': shirts_images})\n",
    "df_shirts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6c3d43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
